# Save this as conf/sweep.yaml
defaults:
  - finetune  # Import the base configuration first
  - override hydra/sweeper: optuna
  - _self_ 
hydra:
  sweeper:
    sampler:
      seed: 123
    direction: minimize
    study_name: finetune_optimization
    storage: null  # Use in-memory storage
    n_trials: 15
    n_jobs: 1  # Run one trial at a time for stability
    params:
      dpl_model.nn_model.learning_rate: choice(0.5, 0.9, 1.0, 1.1, 1.5, 2.0)
      dpl_model.nn_model.hidden_size: choice(256, 512, 1024, 2048)
      dpl_model.nn_model.dropout: choice(0.1, 0.2, 0.25, 0.3, 0.4)
      train.batch_size: choice(50,64,124,100)
      dpl_model.nn_model.num_enc_layers: choice(2, 4, 6, 8, 16)
      dpl_model.nn_model.num_dec_layers: choice(4, 8, 12, 16, 32)

# Override the number of epochs for faster trials
train:
  epochs: 25